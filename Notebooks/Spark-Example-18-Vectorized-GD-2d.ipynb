{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0, 5]), array([1, 6]), array([2, 7]), array([3, 8]), array([4, 9])]\n",
      "[-5.  -3.5 -2.  -0.5  1. ]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import psutil\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "\n",
    "# We create a very simple data set with 5 data items in it. \n",
    "size= 5\n",
    "\n",
    "# mu, sigma = 100, 5000 # mean and standard deviation\n",
    "# error=np.random.normal(mu, sigma, size)\n",
    "\n",
    "x1 = np.arange(0, size)\n",
    "# x2 = np.arange(1, size)\n",
    "x2 = np.arange(5, 5+size)\n",
    "# y = 2.5*x1 + error\n",
    "y1=2.5 * x1\n",
    "y2 =-1 *x2\n",
    "# y = 2*x1 + 10* x2\n",
    "x = []\n",
    "for i in range(size):\n",
    "    x.append(np.array([x1[i],x2[i]]))\n",
    "\n",
    "y = y1+y2\n",
    "# plt.plot(x1, y, 'o', markersize=2)\n",
    "# plt.show()\n",
    "\n",
    "print(x)\n",
    "# print(x2)\n",
    "# print(error)\n",
    "print(y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 m= [0. 0.]  Cost= 42.5\n",
      "4 m= [-0.01 -0.11]  Cost= 33.5645\n",
      "4 m= [-0.0018 -0.1623]  Cost= 31.392868550000003\n",
      "4 m= [ 0.014276 -0.189239]  Cost= 30.532238746894997\n",
      "4 m= [ 0.03369768 -0.20501127]  Cost= 29.932011752353187\n",
      "4 m= [ 0.05447762 -0.21584715]  Cost= 29.38965773095855\n",
      "4 m= [ 0.07574451 -0.22448152]  Cost= 28.86602394426417\n",
      "4 m= [ 0.09711688 -0.23211507]  Cost= 28.353433547975342\n",
      "4 m= [ 0.11842828 -0.23927508]  Cost= 27.850275694662844\n",
      "4 m= [ 0.1396066  -0.24619332]  Cost= 27.35611045054374\n",
      "4 m= [ 0.16062113 -0.25297178]  Cost= 26.87072575002126\n",
      "4 m= [ 0.18145935 -0.25965555]  Cost= 26.39395568369584\n",
      "4 m= [ 0.20211668 -0.26626472]  Cost= 25.925645452726474\n",
      "4 m= [ 0.22259203 -0.27280838]  Cost= 25.465644578160983\n",
      "4 m= [ 0.24288585 -0.27929083]  Cost= 25.013805554089178\n",
      "4 m= [ 0.26299923 -0.28571424]  Cost= 24.56998355019686\n",
      "4 m= [ 0.28293356 -0.29207986]  Cost= 24.134036317153765\n",
      "4 m= [ 0.30269032 -0.2983885 ]  Cost= 23.70582413173796\n",
      "4 m= [ 0.32227106 -0.30464082]  Cost= 23.28520975026551\n",
      "4 m= [ 0.34167733 -0.31083737]  Cost= 22.872058364258823\n",
      "4 m= [ 0.36091067 -0.31697868]  Cost= 22.466237557173706\n",
      "4 m= [ 0.37997262 -0.32306526]  Cost= 22.06761726194651\n",
      "4 m= [ 0.3988647 -0.3290976]  Cost= 21.67606971930476\n",
      "4 m= [ 0.41758843 -0.33507617]  Cost= 21.291469436819334\n",
      "4 m= [ 0.43614532 -0.34100148]  Cost= 20.913693148683592\n",
      "4 m= [ 0.45453683 -0.34687397]  Cost= 20.542619776206212\n",
      "4 m= [ 0.47276446 -0.35269414]  Cost= 20.178130389005027\n",
      "4 m= [ 0.49082965 -0.35846244]  Cost= 19.820108166889383\n",
      "4 m= [ 0.50873387 -0.36417934]  Cost= 19.468438362418862\n",
      "4 m= [ 0.52647853 -0.3698453 ]  Cost= 19.12300826412628\n"
     ]
    }
   ],
   "source": [
    "learningRate = 0.01\n",
    "num_iteration = 30 \n",
    "m_current=np.zeros(2)\n",
    "\n",
    "n = float(size)\n",
    "# print(\"Sample size\", n)\n",
    "\n",
    "# Let's start with main iterative part of gradient descent algorithm \n",
    "for i in range(num_iteration):\n",
    "    \n",
    "    # Calculate the prediction with current regression coefficients. \n",
    "    cost = 0\n",
    "    m_gradient = 0\n",
    "    \n",
    "    for i in range(size):\n",
    "        \n",
    "        y_prediction = np.dot(m_current,x[i])\n",
    "    \n",
    "    \n",
    "    # We compute costs just for monitoring \n",
    "        cost += ( y[i] - y_prediction)**2\n",
    "\n",
    "    # calculate gradients.\n",
    "        m_gradient += x[i] * (y[i] - y_prediction)\n",
    "    \n",
    "    m_gradient = (-1.0/n)* m_gradient\n",
    "    \n",
    "    print(i , \"m=\", m_current, \" Cost=\", cost)\n",
    "        \n",
    "    # update the weights - Regression Coefficients \n",
    "    m_current = m_current - learningRate * m_gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 5], [1, 6], [2, 7], [3, 8], [4, 9]]\n",
      "[-5.0, -3.5, -2.0, -0.5, 1.0]\n",
      "0 Beta [0. 0.]  Cost 42.5\n",
      "1 Beta [-0.01 -0.11]  Cost 33.5645\n",
      "2 Beta [-0.0018 -0.1623]  Cost 31.392868550000003\n",
      "3 Beta [ 0.014276 -0.189239]  Cost 30.532238746894997\n",
      "4 Beta [ 0.03369768 -0.20501127]  Cost 29.932011752353187\n",
      "5 Beta [ 0.05447762 -0.21584715]  Cost 29.38965773095855\n",
      "6 Beta [ 0.07574451 -0.22448152]  Cost 28.86602394426417\n",
      "7 Beta [ 0.09711688 -0.23211507]  Cost 28.353433547975342\n",
      "8 Beta [ 0.11842828 -0.23927508]  Cost 27.850275694662844\n",
      "9 Beta [ 0.1396066  -0.24619332]  Cost 27.35611045054374\n",
      "10 Beta [ 0.16062113 -0.25297178]  Cost 26.87072575002126\n",
      "11 Beta [ 0.18145935 -0.25965555]  Cost 26.39395568369584\n",
      "12 Beta [ 0.20211668 -0.26626472]  Cost 25.925645452726474\n",
      "13 Beta [ 0.22259203 -0.27280838]  Cost 25.465644578160983\n",
      "14 Beta [ 0.24288585 -0.27929083]  Cost 25.013805554089178\n",
      "15 Beta [ 0.26299923 -0.28571424]  Cost 24.56998355019686\n",
      "16 Beta [ 0.28293356 -0.29207986]  Cost 24.134036317153765\n",
      "17 Beta [ 0.30269032 -0.2983885 ]  Cost 23.70582413173796\n",
      "18 Beta [ 0.32227106 -0.30464082]  Cost 23.28520975026551\n",
      "19 Beta [ 0.34167733 -0.31083737]  Cost 22.872058364258823\n",
      "20 Beta [ 0.36091067 -0.31697868]  Cost 22.466237557173706\n",
      "21 Beta [ 0.37997262 -0.32306526]  Cost 22.06761726194651\n",
      "22 Beta [ 0.3988647 -0.3290976]  Cost 21.67606971930476\n",
      "23 Beta [ 0.41758843 -0.33507617]  Cost 21.291469436819334\n",
      "24 Beta [ 0.43614532 -0.34100148]  Cost 20.913693148683592\n",
      "25 Beta [ 0.45453683 -0.34687397]  Cost 20.542619776206212\n",
      "26 Beta [ 0.47276446 -0.35269414]  Cost 20.178130389005027\n",
      "27 Beta [ 0.49082965 -0.35846244]  Cost 19.820108166889383\n",
      "28 Beta [ 0.50873387 -0.36417934]  Cost 19.468438362418862\n",
      "29 Beta [ 0.52647853 -0.3698453 ]  Cost 19.12300826412628\n"
     ]
    }
   ],
   "source": [
    "# Now we do gradient Decent on our RDD data set. \n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pandas import Series,DataFrame\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "learningRate = 0.01\n",
    "num_iteration = 30\n",
    "\n",
    "beta = np.zeros(2)\n",
    "# print(beta)\n",
    "x1 = [0,1,2,3,4]\n",
    "# x2 = np.arange(1, size)\n",
    "x2 = [5,6,7,8,9]\n",
    "# y = 2.5*x1 + error\n",
    "y1 = [i * 2.5 for i in x1]\n",
    "y2 = [i * -1 for i in x2]\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "for i in range(size):\n",
    "    x.append([x1[i],x2[i]])\n",
    "    y.append(y1[i]+y2[i])\n",
    "    \n",
    "\n",
    "\n",
    "# plt.plot(x1, y, 'o', markersize=2)\n",
    "# plt.show()\n",
    "\n",
    "print(x)\n",
    "# print(x2)\n",
    "# print(error)\n",
    "print(y)\n",
    "\n",
    "data = {'y':y,\n",
    "       'x':x}\n",
    "df = DataFrame(data)\n",
    "\n",
    "spark_df_from_pandas = spark.createDataFrame(df, schema=['x', 'y'])\n",
    "# df = np.stack([y, x], axis=1)\n",
    "# print(df)\n",
    "# dff = map(lambda x: (float(x[0]), Vectors.dense(x[1:])), df)\n",
    "# mydf = spark.createDataFrame(dff, schema=[\"label\", \"features\"])\n",
    "\n",
    "\n",
    "\n",
    "# # Now, we create an RDD from this data. \n",
    "# # X is a numpy array \n",
    "# # y is a simple value lable\n",
    "myRDD=spark_df_from_pandas.rdd.map(lambda x: (float(x[0]), np.array(x[1]) ))\n",
    "\n",
    "\n",
    "# # Let's start with main iterative part of gradient descent algorithm \n",
    "for i in range(num_iteration):\n",
    "    \n",
    "    gradientCost=myRDD.map(lambda x: (x[1], (x[0] - np.dot(x[1] , beta) )))\\\n",
    "                           .map(lambda x: (x[0]*x[1], x[1]**2 )).reduce(lambda x, y: (x[0] +y[0], x[1]+y[1] ))\n",
    "    \n",
    "    cost= gradientCost[1]\n",
    "    \n",
    "    gradient=(-1/float(size))* gradientCost[0]\n",
    "    \n",
    "    print(i, \"Beta\", beta, \" Cost\", cost)\n",
    "    beta = beta - learningRate * gradient\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
